<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="ğ•olver: Multi-Agent Reasoning with Holistic Experience Learning Just Like an Olympiad Team">
  <meta name="keywords" content="ğ•olver, Multi-Agent Reasoning, Language Models, Experience Learning, Mathematics, Programming">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>ğ•olver: Multi-Agent Reasoning with Holistic Experience Learning Just Like an Olympiad Team</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Noto+Sans+Math|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/storm.png">

  <script src="https://unpkg.com/marked@15.0.8/marked.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
</nav>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">
            <span class="x-title">ğ•</span>olver: Multi-Agent Reasoning with Holistic Experience Learning Just Like an Olympiad Team
          </h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=3YexY9gAAAAJ&hl=en" target="_blank" rel="noopener noreferrer">Md. Tanzib Hosain</a><sup style="color: green">1*</sup>,</span>
            <span class="author-block">
              <a href="https://salmanrahman.net/" target="_blank" rel="noopener noreferrer">Salman Rahman</a><sup style="color: green">2*</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=pjn3jg4AAAAJ&hl=en" target="_blank" rel="noopener noreferrer">Md Kishor Morol</a><sup>3</sup>,</span>
            <span class="author-block">
              <a href="https://rizwan09.github.io/" target="_blank" rel="noopener noreferrer">Md Rizwan Parvez</a><sup style="color: orangered">4</sup></span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>American International University-Bangladesh,</span>
            <span class="author-block"><sup>2</sup>University of California, Los Angeles,</span>
            <span class="author-block"><sup>3</sup>Cornell University,</span>
            <span class="author-block"><sup style="color: orangered">4</sup>Qatar Computing Research Institute</span>
            <br></br>
            <span class="author-block"><sup style="color: green">*</sup> Work done when working as a remote RA at QCRI.</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2504.13203" target="_blank" rel="noopener noreferrer"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2504.13203" target="_blank" rel="noopener noreferrer"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/kraritt/Xolver" target="_blank" rel="noopener noreferrer"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Abstract Section -->  
<section class="section" id="abstract">
  <div class="container is-max-desktop">
    <div class="content has-text-justified">
      <h2 id="insights" class="title is-3 has-text-centered">Abstract <a class="is-size-5" href="#abstract"><i class="fas fa-link"></i></a></h2>
      <p>
        Despite impressive progress on complex reasoning, current large language models (LLMs) typically operate in isolationâ€”treating each problem as an independent attempt, without accumulating or integrating experiential knowledge. In contrast, expert problem solversâ€”such as Olympiad or programming contest teamsâ€”leverage a rich tapestry of experiences: absorbing mentorship from coaches, developing intuition from past problems, leveraging knowledge of tool usage and library functionality, adapting strategies based on the expertise and experiences of peers, continuously refining their reasoning through trial and error, and learning from other related problems even during competition.
        Inspired by this, we introduce ğ•olverâ€”a training-free, multi-agent reasoning framework that equips a black-box LLM with a persistent, evolving memory of holistic experience. ğ•olver integrates diverse experience modalities, including external and self-retrieval, tool use, agent collaboration, self-evaluation, and iterative refinement. By learning from relevant strategies, code fragments, and abstract reasoning patterns at inference time, ğ•olver avoids generating solutions from scratchâ€”marking a transition from isolated inference toward experience-aware language agents.
        Built on both open-weight and proprietary models, ğ•olver consistently outperforms specialized reasoning agents (e.g., OctoTools, CheatSheet, Search-o1). Even when instantiated with lightweight backbones (e.g., QWQ-32B), it often surpasses the most advanced models to dateâ€”including Qwen3-235B, Gemini 2.5 Pro, o3, and o4-mini-high. With a stronger backbone like o3-mini-high, it achieves a new best resultâ€”<span class="has-text-weight-bold">98.1% on GSM8K, 94.4% on AIME'24, 93.7% on AIME'25, 99.8% on Math-500, and 91.6% on LiveCodeBench</span>â€”highlighting holistic experience learning as a key step toward dynamic, generalist agents capable of expert-level reasoning.
      </p>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Framework Figure. -->
    <div class="content has-text-justified">
      <div class="column is-full-width">
        <img src="./static/images/framework.png" alt="ğ•olver Framework"
             class="framework-image"/>
        <p>
          <span class="has-text-weight-bold">ğ•olver Scaffold.</span> At each iteration, agents receive their past reasoning history and top ranked exemplars to generate new thoughts and responses, using tools (e.g., code) as needed. A judge model ranks outputs, and an intermediate memory maintains the best responses over time. Exemplars are initialized via episodic retrieval and continually updated with high-quality solutions from the memory. Iteration stops when convergence or max steps are reached, followed by final verification.
        </p>
      </div>
    </div>
    <!--/ Framework Figure. -->
  </div>
</section>

<!-- Results Table Section -->
<section class="section" id="results">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 id="results" class="title is-3 has-text-centered">Results <a class="is-size-5" href="#results"><i class="fas fa-link"></i></a></h2>
        <div class="content has-text-centered">
          <div class="table-container">
            <table class="table is-bordered is-striped is-fullwidth is-hoverable">
              <thead>
                <tr>
                  <th>Model</th>
                  <th>Appr.</th>
                  <th>GSM8K</th>
                  <th>AIME '24</th>
                  <th>AIME '25</th>
                  <th>Math-500</th>
                  <th>LiveCodeBench (v5)</th>
                </tr>
              </thead>
              <tbody>
                <tr class="has-background-light">
                  <td colspan="7"><strong>Proprietary Models</strong></td>
                </tr>
                <tr><td>Claude 3.7 Sonnet T.</td><td>LongCoT</td><td>â€“</td><td>61.3</td><td>49.5</td><td>96.2</td><td>51.4</td></tr>
                <tr><td>Grok-3 (Beta) T.</td><td>Direct</td><td>â€“</td><td>83.9</td><td>77.3</td><td>â€“</td><td>70.6</td></tr>
                <tr><td>Grok-3-mini (Beta) T.</td><td>LongCoT</td><td>â€“</td><td>89.5</td><td>82.0</td><td>â€“</td><td>-</td></tr>
                <tr><td>Gemini 2.5 Flash T.</td><td>LongCoT</td><td>â€“</td><td>88.0</td><td>78.0</td><td>â€“</td><td>63.5</td></tr>
                <tr><td>o1</td><td>LongCoT</td><td>96.4</td><td>74.3</td><td>79.2</td><td>96.4</td><td>71.0</td></tr>
                <tr><td>o3-mini-high</td><td>LongCoT</td><td>â€“</td><td>87.3</td><td>86.5</td><td>â€“</td><td>69.5</td></tr>
                <tr><td>Gemini 2.5 Pro.</td><td>Direct</td><td>â€“</td><td>92.0</td><td>86.7</td><td>â€“</td><td>70.4</td></tr>
                <tr><td>o3</td><td>LongCoT</td><td>96.7</td><td>91.6</td><td>88.9</td><td>â€“</td><td>â€“</td></tr>
                <tr><td>o4-mini-high</td><td>LongCoT</td><td>â€“</td><td>93.4</td><td><strong>92.7</strong></td><td>â€“</td><td>69.5</td></tr>

                <tr class="has-background-light">
                  <td colspan="7"><strong>Open Weights Models</strong></td>
                </tr>
                <tr><td>DeepSeek-R1</td><td>LongCoT</td><td>â€“</td><td>79.8</td><td>70.0</td><td>97.3</td><td>64.3</td></tr>
                <tr><td>Qwen3-235B-A22B</td><td>LongCoT</td><td>â€“</td><td>85.7</td><td>81.5</td><td>â€“</td><td>70.7</td></tr>

                <tr class="has-background-light">
                  <td colspan="7"><strong>Math/Code Specialized Models</strong></td>
                </tr>
                <tr class="has-background-grey-lighter"><td>rStar-Math (Best)</td><td>-</td><td>95.2</td><td>53.3</td><td>â€“</td><td>90.0</td><td>â€“</td></tr>
                <tr class="has-background-grey-lighter"><td>OpenMathReason (Best)</td><td>-</td><td>â€“</td><td>93.3</td><td>80.0</td><td>â€“</td><td>â€“</td></tr>
                <tr class="has-background-white"><td>AlphaOne (Best)</td><td>-</td><td>-</td><td>53.3</td><td>-</td><td>89.4</td><td>75.8</td></tr>
                <tr class="has-background-grey-light"><td>OpenCodeReason (Best)</td><td>-</td><td>â€“</td><td>â€“</td><td>â€“</td><td>â€“</td><td>61.8</td></tr>
                <tr class="has-background-grey-light"><td>rStar-Coder (Best)</td><td>-</td><td>â€“</td><td>â€“</td><td>â€“</td><td>â€“</td><td>62.5</td></tr>
                <tr class="has-background-grey-light"><td>Kimi-k1.6-IOI-high</td><td>-</td><td>â€“</td><td>â€“</td><td>â€“</td><td>â€“</td><td>73.8</td></tr>

                <tr class="has-background-light">
                  <td colspan="7"><strong>Reasoning Agents/Frameworks</strong></td>
                </tr>
                <tr><td rowspan="8">o3-mini-medium</td><td>LongCoT</td><td>95.2</td><td>75.8</td><td>70.4</td><td>97.3</td><td>66.3</td></tr>
                <tr><td>Self-Refl.</td><td>93.1</td><td>79.4</td><td>76.5</td><td>95.2</td><td>73.2</td></tr>
                <tr><td>OctoTools</td><td>95.4</td><td>81.7</td><td>75.3</td><td>97.5</td><td>â€“</td></tr>
                <tr><td>Search-o1</td><td>95.8</td><td>81.8</td><td>76.7</td><td>97.6</td><td>73.6</td></tr>
                <tr><td>CheatSheet</td><td>95.9</td><td>82.2</td><td>75.8</td><td>97.7</td><td>â€“</td></tr>
                <tr><td>CodeSim</td><td>â€“</td><td>â€“</td><td>â€“</td><td>â€“</td><td>73.8</td></tr>
                <tr class="has-background-info-light"><td><strong>ğ•olver (â€“)</strong></td><td>95.6</td><td>87.2</td><td>85.1</td><td><u>97.7</u></td><td>79.6</td></tr>
                <tr class="has-background-info-light"><td><strong>ğ•olver (+)</strong></td><td><u>97.1</u></td><td><strong>93.8</strong></td><td><u>89.4</u></td><td><strong>99.2</strong></td><td><strong>87.3</strong></td></tr>
                
                <tr><td rowspan="8">QWQ-32B</td><td>LongCoT</td><td>96.1</td><td>78.1</td><td>65.8</td><td>83.2</td><td>63.4</td></tr>
                <tr><td>Self-Refl.</td><td>94.0</td><td>79.3</td><td>66.3</td><td>80.4</td><td>69.2</td></tr>
                <tr><td>OctoTools</td><td>96.3</td><td>83.0</td><td>71.7</td><td>86.1</td><td>â€“</td></tr>
                <tr><td>Search-o1</td><td>96.4</td><td>84.4</td><td>71.8</td><td>87.1</td><td>69.3</td></tr>
                <tr><td>CheatSheet</td><td>96.8</td><td>83.5</td><td>72.2</td><td>86.5</td><td>â€“</td></tr>
                <tr><td>CodeSim</td><td>â€“</td><td>â€“</td><td>â€“</td><td>â€“</td><td>70.5</td></tr>
                <tr class="has-background-info-light"><td><strong>ğ•olver (â€“)</strong></td><td>96.5</td><td>89.9</td><td>79.5</td><td>93.1</td><td>76.2</td></tr>
                <tr class="has-background-info-light"><td><strong>ğ•olver (+)</strong></td><td><strong>98.0</strong></td><td><u>93.6</u></td><td>82.7</td><td>95.5</td><td><u>79.2</u></td></tr>

                <tr class="has-background-success-light">
                  <td>o3-mini-high</td>
                  <td><strong>ğ•olver (+)</strong></td>
                  <td><strong>98.1</strong></td>
                  <td><strong>94.4</strong></td>
                  <td><strong>93.7</strong></td>
                  <td><strong>99.8</strong></td>
                  <td><strong>91.6</strong></td>
                </tr>
              </tbody>
            </table>
          </div>
        </div>
        <p>
          ğ•olver against SoTA reasoning models, specialized models, and other reasoning agents across mathematical and coding tasks. Best results are boldfaced and second-best results are underlined. T: Think models. LongCoT*: standard prompting for reasoning models. "â€“" denotes either n/a (e.g., only math/code specialized models) or results not reported.
        </p>
      </div>
    </div>
  </div>
</section>
  
<section class="section" id="collaboration">
  <div class="container is-max-desktop">
    <!-- Collaboration Figure. -->
    <div class="content has-text-justified">
      <h2 id="collaboration" class="title is-3 has-text-centered">Performance with Increasing Agents and Iterations <a class="is-size-5" href="#collaboration"><i class="fas fa-link"></i></a></h2>
      <div class="column is-full-width">
        <img src="./static/images/collaboration.png" alt="ğ•olver Collaboration"
             class="collaboration-image"/>
        <p>
          We analyze the effect of varying the number of agents and reasoning iterations on ğ•olver's performance. In a controlled setup, we fix one variable (e.g., 3 agents or 2 iterations) and incrementally increase the other. Performance improves consistently on both AIME â€™25 and LIVECODEBENCH with more agents or iterations. To probe deeper, we conduct a budget-controlled experiment on the AIME â€™25 dataset, where the total reasoning budget (i.e., number of agents Ã— number of iterations) is fixed. While iterative reasoning remains a crucial factor for ğ•olver's performance, we find that increasing the number of agentsâ€”particularly beyond a minimum of threeâ€”yields additional, emergent improvements, leading to over a 4% performance gain.
        </p>
      </div>
    </div>
    <!--/ Collaboration Figure. -->
  </div>
</section>

<section class="section" id="agreemant">
  <div class="container is-max-desktop">
    <!-- Agreement Figure. -->
    <div class="content has-text-justified">
      <h2 id="agreemant" class="title is-3 has-text-centered">Case Study: How ğ•olver Enhance Reasoning <a class="is-size-5" href="#agreemant"><i class="fas fa-link"></i></a></h2>
      <div class="column is-full-width">
        <img src="./static/images/agreement.png" alt="ğ•olver Agreement"
             class="agreement-image"/>
        <p>
          We conduct an in-depth analysis combining qualitative runtime inspection with controlled experiments. We begin by manually studying Xolverâ€™s agent interaction traces on AIME '25 and LiveCodeBench. These case studies reveal that at each iteration, dynamic agents attempt to improve upon earlier failures by leveraging Judge agent feedback and by aligning with top-ranked outputs
          stored in the shared memory. This process results in progressively refined outputs, increased
          agent alignment, and eventual convergence toward correct solutions. To verify this behavior systematically, we conduct a controlled experiment across both math and
          code tasks. We instantiate two dynamic agents with complementary strengths: a Coder agent and a
          Mathematician agent, each proficient in one domain but suboptimal in the other. We then measure
          their performance and agreement across iterationsâ€”defined as the percentage of problems in which
          both agents independently produce the same correct answer (for math) or code that passes the
          same test cases (for code). Both agents demonstrate consistent accuracy
          improvements over time, accompanied by a rising agreement rate.
        </p>
      </div>
    </div>
    <!--/ Agreement Figure. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered">Reasoning Patterns in ğ•olver Traces</h2>
        <div class="table-container">
        <table class="table is-bordered is-striped is-fullwidth is-hoverable">
        <thead>
          <tr>
            <th rowspan="2"><strong>Reasoning Pattern</strong></th>
            <th colspan="2"><strong>Correct Solutions</strong></th>
            <th colspan="2"><strong>Incorrect Solutions</strong></th>
          </tr>
          <tr>
            <th>Easy â†’ Medium</th>
            <th>Medium â†’ High</th>
            <th>Easy â†’ Medium</th>
            <th>Medium â†’ High</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>Self-Evaluation (â†‘)</td>
            <td><u><span style="color:green;">0.35 â†’ 0.38</span></u></td>
            <td><u><span style="color:green;">0.38 â†’ 0.40</span></u></td>
            <td><u>0.35 â†’ 0.37</u></td>
            <td><u><span style="color:green;">0.32 â†’ 0.35</span></u></td>
          </tr>
          <tr>
            <td>New Approach (â†‘)</td>
            <td><span style="color:green;">0.18 â†’ 0.21</span></td>
            <td><span style="color:green;">0.21 â†’ 0.24</span></td>
            <td><span style="color:green;">0.17 â†’ 0.24</span></td>
            <td><span style="color:green;">0.24 â†’ 0.26</span></td>
          </tr>
          <tr>
            <td>Problem Rephrasing (â†“â†‘)</td>
            <td><span style="color:red;">0.20 â†’ 0.17</span></td>
            <td>0.18 â†’ 0.18</td>
            <td>0.23 â†’ 0.24</td>
            <td><span style="color:green;">0.24 â†’ 0.25</span></td>
          </tr>
          <tr>
            <td>Subgoal Setup (â†“â†‘)</td>
            <td><span style="color:red;">0.14 â†’ 0.13</span></td>
            <td><span style="color:red;">0.13 â†’ 0.11</span></td>
            <td><u><span style="color:green;">0.11 â†’ 0.12</span></u></td>
            <td><u>0.11 â†’ 0.11</u></td>
          </tr>
        </tbody>
      </table>
    </div>
    <p class="is-size-6 mt-3">
      Changes in major reasoning pattern frequencies as problem difficulty increases in LiveCodeBench, comparing correct vs. incorrect solutions.
      <span style="color:green;"><strong>Green</strong></span> and 
      <span style="color:red;"><strong>red</strong></span> indicate statistically significant increases or decreases (p &lt; 0.05). 
      <u>Underlined</u> cells highlight patterns where ğ•olver improves over OpenCodeReasoning, which otherwise shows a declining trend.
      Direction arrows denote: â†‘ = increase, â†“ = decrease, â†“â†‘ = mixed trend (decrease in correct, increase in incorrect). ğ•olver increases use of self-evaluation and new approaches with task difficulty, and demonstrates targeted subgoal setup and problem rephrasing when solutions failâ€”reflecting its adaptive, collaborative reasoning.
    </p>
  </div>
      </div>
    </div>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{hosain2025xolver,
      title={ğ•olver: Multi-Agent Reasoning with Holistic Experience Learning Just Like an Olympiad Team}, 
      author={Md. Tanzib Hosain and Salman Rahman and Md Kishor Morol and Md Rizwan Parvez},
      journal={arXiv preprint},
      year={2025}
}</code></pre>
  </div>
</section>

<!-- Organization Logos Section -->
<section class="section" id="org-logos">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column has-text-centered">
        <div class="org-logos" style="margin: 2rem 0;">
          <a href="https://www.aiub.edu/" target="_blank" rel="noopener noreferrer">
            <img src="static/images/logo/aiub-logo.png" alt="AIUB Logo" class="org-logo" style="height: 120px;">
          </a>
          <a href="https://www.ucla.edu/" target="_blank" rel="noopener noreferrer">
            <img src="static/images/logo/ucla-logo.png" alt="UCLA Logo" class="org-logo" style="height: 60px;">
          </a>
          <a href="https://www.cornell.edu/" target="_blank" rel="noopener noreferrer">
            <img src="static/images/logo/cornell-university-logo.png" alt="Cornell Logo" class="org-logo" style="height: 120px;">
          </a>
          <a href="https://www.hbku.edu.qa/en/qcri" target="_blank" rel="noopener noreferrer">
            <img src="static/images/logo/QCRI-Logo.jpeg" alt="QCRI Logo" class="org-logo" style="height: 80px;">
          </a>
        </div>
      </div>
    </div>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <p>
        This website is adapted from <a href="https://nerfies.github.io" target="_blank" rel="noopener noreferrer">Nerfies</a>, licensed under a 
        <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank" rel="noopener noreferrer">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
      </p>
    </div>
  </div>
</footer>

<style>
.footer {
    padding: 3rem 1.5rem;
    margin-top: 2rem;
}

.footer a {
    color: #485fc7;
    text-decoration: underline;
}

.org-logos {
  display: flex;
  justify-content: center;
  align-items: center;
  flex-wrap: wrap;
  gap: 2rem;
}

.org-logo {
  height: 70px;
  object-fit: contain;
  margin: 0 2.5rem;
  transition: transform 0.2s ease;
}

.org-logo:hover {
  transform: scale(1.05);
}

@media screen and (max-width: 768px) {
  .org-logo {
    height: 50px;
    margin: 1rem;
  }
}
</style>

</body>
</html>
